defaults:
  - dataset: gen1
#  - model: rnndet
  - _self_
# dataset:
#   path: 


model:
  name: rnndet
  backbone:
    name: MaxViTRNN
    compile:
      enable: False
      args:
        mode: reduce-overhead
    input_channels: 20
    enable_masking: False
    partition_split_32: 2
    embed_dim: 64
    dim_multiplier: [1, 2, 4, 8]
    num_blocks: [1, 1, 1, 1]
    T_max_chrono_init: [4, 8, 16, 32]
    stem:
      patch_size: 4
    stage:
      downsample:
        type: patch
        overlap: True
        norm_affine: True
      attention:
        use_torch_mha: False
        partition_size: ???
        dim_head: 32
        attention_bias: True
        mlp_activation: gelu
        mlp_gated: False
        mlp_bias: True
        mlp_ratio: 4
        drop_mlp: 0
        drop_path: 0
        ls_init_value: 1e-5
      lstm:
        dws_conv: False
        dws_conv_only_hidden: True
        dws_conv_kernel_size: 3
        drop_cell_update: 0
  fpn:
    name: PAFPN
    compile:
      enable: False
      args:
        mode: reduce-overhead
    depth: 0.67 # round(depth * 3) == num bottleneck blocks
    # stage 1 is the first and len(num_layers) is the last
    in_stages: [2, 3, 4]
    depthwise: False
    act: "silu"
  head:
    name: YoloX
    compile:
      enable: False
      args:
        mode: reduce-overhead
    depthwise: False
    act: "silu"
  postprocess:
    confidence_threshold: 0.25
    nms_threshold: 0.45


checkpoint: "checkpoints/gen_rvt-b.ckpt"
use_test_set: False
hardware:
  num_workers: 1
  eval: 4
  gpus: 0 # GPU idx (multi-gpu not supported for validation)
batch_size:
  eval: 8
training:
  precision: 16

experiment:
  gen1: base.yaml

# event_simulator:
#   model: "generator"
#   model-dir: Model/generatorMVSEC.pth
#   data-simu: "/home/lgx/data/whitebox_attack/train/"
#   reshape-size: 240,180 
#   frame_num: 3
#   size: (5,5)
#   debug: 'store_true' # debug mode 
#   dl: 0 #'crop the image')
#   dr: 281 # 'crop the image')
#   data-size: 20 #,help='path where image.txt lies')
#   save-dir: './Model/TrainingModels/23/' #,help='savedir for models')#old20201126
#   tb-path: './Model/TrainingModels/23/' #,help='savedir for tensorboardX')#old20201126
#   contrast_threshold_pos: 0.1
#   contrast_threshold_neg: 0.1
#   g-lr: 4e-4
#   d-lr: 4e-4
#   train-g-interval: 5
#   num-epochs: 10
#   num-workers: 16
#   batch-size: 1
#   d-batch-size: 256
#   epoch-save: 5 #    #You can use this value to save model every X epochs
#   show-interval: 1 #
#   steps-loss: 20 
#   warmup: 0
#   lr-end: 1e-5
#   trainstep: 100

#   minimum-threshold', type=float, default=0.01)

#         self.parser.add_argument("--patch", type=int, default=4, help="image patch size")

#         self.parser.add_argument("--use-log-images", default=True, help="irradiance maps = log(gray map)")
#         self.parser.add_argument("--log-eps", type=int, default=0.001, help="E = log(L/255+eps)")
#         self.parser.add_argument("--log-threshold", type=int, default=20, help="x>=T E = log(L) or x<T E = L/Tlog(T)")
        
#         self.parser.add_argument("--clamp-num", type=float, default=0.01, help="WGAN clip gradient")
#         self.parser.add_argument("--gp-lambda", type=float, default=1, help="WGAN gradient penalty")
#         self.parser.add_argument("--min-event-num", type=float, default=10, help="avoid all black")
        